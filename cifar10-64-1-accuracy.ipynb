{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n# for dirname, _, filenames in os.walk('/kaggle/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-07-16T08:46:33.692434Z","iopub.execute_input":"2023-07-16T08:46:33.693022Z","iopub.status.idle":"2023-07-16T08:46:33.699223Z","shell.execute_reply.started":"2023-07-16T08:46:33.692981Z","shell.execute_reply":"2023-07-16T08:46:33.698113Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"import glob\nimport tqdm as tqdm\nimport random\nimport tensorflow as tf\nfrom tensorflow import keras","metadata":{"execution":{"iopub.status.busy":"2023-07-16T08:51:02.115665Z","iopub.execute_input":"2023-07-16T08:51:02.116101Z","iopub.status.idle":"2023-07-16T08:51:02.121793Z","shell.execute_reply.started":"2023-07-16T08:51:02.116042Z","shell.execute_reply":"2023-07-16T08:51:02.120554Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"column_names=[\"file_path\",\"label\"]\ntrain=pd.DataFrame(columns=column_names)\ntest=pd.DataFrame(columns=column_names)","metadata":{"execution":{"iopub.status.busy":"2023-07-16T08:51:02.404888Z","iopub.execute_input":"2023-07-16T08:51:02.405930Z","iopub.status.idle":"2023-07-16T08:51:02.423712Z","shell.execute_reply.started":"2023-07-16T08:51:02.405895Z","shell.execute_reply":"2023-07-16T08:51:02.422707Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"for df,folder in zip([train,test],['train','test']):\n    file_paths=glob.glob(\"/kaggle/input/cifar10/cifar10/\"+folder+\"/*/*\")\n    df['file_path']=file_paths\n    labels=[]\n    for file_path in tqdm.tqdm(file_paths):\n        label=file_path.split('_')[-1].split('.')[0]\n        labels.append(label)\n    df['label']=labels","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2023-07-16T08:51:02.636616Z","iopub.execute_input":"2023-07-16T08:51:02.636983Z","iopub.status.idle":"2023-07-16T08:51:10.548968Z","shell.execute_reply.started":"2023-07-16T08:51:02.636943Z","shell.execute_reply":"2023-07-16T08:51:10.548022Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stderr","text":"100%|██████████| 50000/50000 [00:00<00:00, 676753.88it/s]\n100%|██████████| 10000/10000 [00:00<00:00, 700393.09it/s]\n","output_type":"stream"}]},{"cell_type":"code","source":"train","metadata":{"execution":{"iopub.status.busy":"2023-07-16T08:51:10.550810Z","iopub.execute_input":"2023-07-16T08:51:10.552325Z","iopub.status.idle":"2023-07-16T08:51:10.569907Z","shell.execute_reply.started":"2023-07-16T08:51:10.552287Z","shell.execute_reply":"2023-07-16T08:51:10.568779Z"},"trusted":true},"execution_count":5,"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"                                               file_path     label\n0      /kaggle/input/cifar10/cifar10/train/airplane/2...  airplane\n1      /kaggle/input/cifar10/cifar10/train/airplane/2...  airplane\n2      /kaggle/input/cifar10/cifar10/train/airplane/4...  airplane\n3      /kaggle/input/cifar10/cifar10/train/airplane/1...  airplane\n4      /kaggle/input/cifar10/cifar10/train/airplane/4...  airplane\n...                                                  ...       ...\n49995  /kaggle/input/cifar10/cifar10/train/deer/41608...      deer\n49996  /kaggle/input/cifar10/cifar10/train/deer/6785_...      deer\n49997  /kaggle/input/cifar10/cifar10/train/deer/17777...      deer\n49998  /kaggle/input/cifar10/cifar10/train/deer/9202_...      deer\n49999  /kaggle/input/cifar10/cifar10/train/deer/45749...      deer\n\n[50000 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>file_path</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>/kaggle/input/cifar10/cifar10/train/airplane/2...</td>\n      <td>airplane</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>/kaggle/input/cifar10/cifar10/train/airplane/2...</td>\n      <td>airplane</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>/kaggle/input/cifar10/cifar10/train/airplane/4...</td>\n      <td>airplane</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>/kaggle/input/cifar10/cifar10/train/airplane/1...</td>\n      <td>airplane</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>/kaggle/input/cifar10/cifar10/train/airplane/4...</td>\n      <td>airplane</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>49995</th>\n      <td>/kaggle/input/cifar10/cifar10/train/deer/41608...</td>\n      <td>deer</td>\n    </tr>\n    <tr>\n      <th>49996</th>\n      <td>/kaggle/input/cifar10/cifar10/train/deer/6785_...</td>\n      <td>deer</td>\n    </tr>\n    <tr>\n      <th>49997</th>\n      <td>/kaggle/input/cifar10/cifar10/train/deer/17777...</td>\n      <td>deer</td>\n    </tr>\n    <tr>\n      <th>49998</th>\n      <td>/kaggle/input/cifar10/cifar10/train/deer/9202_...</td>\n      <td>deer</td>\n    </tr>\n    <tr>\n      <th>49999</th>\n      <td>/kaggle/input/cifar10/cifar10/train/deer/45749...</td>\n      <td>deer</td>\n    </tr>\n  </tbody>\n</table>\n<p>50000 rows × 2 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"def final_data(path,label):\n    image = tf.io.read_file(path)\n    image = tf.image.decode_jpeg(image,channels=3)\n    image = tf.image.resize(image,[32,32])\n    image = image/255\n    return image,label","metadata":{"execution":{"iopub.status.busy":"2023-07-16T08:51:10.571617Z","iopub.execute_input":"2023-07-16T08:51:10.571957Z","iopub.status.idle":"2023-07-16T08:51:10.577492Z","shell.execute_reply.started":"2023-07-16T08:51:10.571925Z","shell.execute_reply":"2023-07-16T08:51:10.576553Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"def transform(df,training=False):\n    labels=pd.get_dummies(df.label)\n    preliminary_data=list(zip(df['file_path'],labels.values.tolist()))\n    if(training==True):\n        random.shuffle(preliminary_data)\n    paths,labels=zip(*preliminary_data)\n    data=tf.data.Dataset.from_tensor_slices((list(paths),list(labels)))\n    data=data.map(final_data)\n    return data","metadata":{"execution":{"iopub.status.busy":"2023-07-16T08:51:10.580462Z","iopub.execute_input":"2023-07-16T08:51:10.581191Z","iopub.status.idle":"2023-07-16T08:51:10.588225Z","shell.execute_reply.started":"2023-07-16T08:51:10.581155Z","shell.execute_reply":"2023-07-16T08:51:10.587286Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"train_data=transform(train,training=True)","metadata":{"execution":{"iopub.status.busy":"2023-07-16T08:51:10.589843Z","iopub.execute_input":"2023-07-16T08:51:10.590840Z","iopub.status.idle":"2023-07-16T08:51:13.009522Z","shell.execute_reply.started":"2023-07-16T08:51:10.590802Z","shell.execute_reply":"2023-07-16T08:51:13.008455Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"test_data=transform(test)","metadata":{"execution":{"iopub.status.busy":"2023-07-16T08:51:13.010864Z","iopub.execute_input":"2023-07-16T08:51:13.011655Z","iopub.status.idle":"2023-07-16T08:51:13.413398Z","shell.execute_reply.started":"2023-07-16T08:51:13.011618Z","shell.execute_reply":"2023-07-16T08:51:13.412382Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"test_data=test_data.take(10000)","metadata":{"execution":{"iopub.status.busy":"2023-07-16T08:51:13.415152Z","iopub.execute_input":"2023-07-16T08:51:13.415575Z","iopub.status.idle":"2023-07-16T08:51:13.426556Z","shell.execute_reply.started":"2023-07-16T08:51:13.415533Z","shell.execute_reply":"2023-07-16T08:51:13.425172Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"val_size=round(0.1*50000)\ntrain_size=round(0.9*50000)\ntrain_data=train_data.take(train_size).prefetch(30)\nval_data=train_data.skip(train_size)\nval_data=train_data.take(val_size).prefetch(30)","metadata":{"execution":{"iopub.status.busy":"2023-07-16T08:51:13.428081Z","iopub.execute_input":"2023-07-16T08:51:13.428639Z","iopub.status.idle":"2023-07-16T08:51:13.446213Z","shell.execute_reply.started":"2023-07-16T08:51:13.428578Z","shell.execute_reply":"2023-07-16T08:51:13.445223Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"train_data","metadata":{"execution":{"iopub.status.busy":"2023-07-16T08:51:13.447472Z","iopub.execute_input":"2023-07-16T08:51:13.447887Z","iopub.status.idle":"2023-07-16T08:51:13.457113Z","shell.execute_reply.started":"2023-07-16T08:51:13.447851Z","shell.execute_reply":"2023-07-16T08:51:13.456092Z"},"trusted":true},"execution_count":12,"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"<_PrefetchDataset element_spec=(TensorSpec(shape=(32, 32, 3), dtype=tf.float32, name=None), TensorSpec(shape=(10,), dtype=tf.int32, name=None))>"},"metadata":{}}]},{"cell_type":"code","source":"mirrored_strategy=tf.distribute.MirroredStrategy(devices=[\"/gpu:0\",\"/gpu:1\"])","metadata":{"execution":{"iopub.status.busy":"2023-07-16T08:51:13.460987Z","iopub.execute_input":"2023-07-16T08:51:13.461405Z","iopub.status.idle":"2023-07-16T08:51:13.797103Z","shell.execute_reply.started":"2023-07-16T08:51:13.461371Z","shell.execute_reply":"2023-07-16T08:51:13.796011Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"#model 5\n# with mirrored_strategy.scope():\n#     model=tf.keras.Sequential()\n#     model.add(tf.keras.layers.Conv2D(30,(2,2),strides=(1,1),padding='valid',\n#                                      activation='relu',input_shape=(32,32,3)))\n#     model.add(tf.keras.layers.Conv2D(30,(2,2),strides=(1,1),padding='valid',activation='relu'))\n#     model.add(tf.keras.layers.BatchNormalization())\n#     model.add(tf.keras.layers.MaxPool2D(pool_size=(2,2),strides=None,padding='valid'))\n# #   model.add(tf.keras.layers.Conv2D(20,(2,2),strides=(1,1),padding='valid',activation='relu'))\n#     model.add(tf.keras.layers.Conv2D(15,(3,3),strides=(1,1),padding='valid',activation='relu'))\n# #     model.add(tf.keras.layers.Conv2D(15,(3,3),strides=(1,1),padding='valid',activation='relu'))\n#     model.add(tf.keras.layers.GroupNormalization(groups=3))\n#     model.add(tf.keras.layers.MaxPool2D(pool_size=(2,2),strides=None,padding='valid'))\n#     model.add(tf.keras.layers.Conv2D(10,(3,3),strides=(1,1),padding='valid',activation='relu'))\n#     model.add(tf.keras.layers.Flatten())\n#     model.add(tf.keras.layers.Normalization())\n#     model.add(tf.keras.layers.Dense(128,activation='relu')) #reduce neurons?\n#     model.add(tf.keras.layers.BatchNormalization())\n#     model.add(tf.keras.layers.Dropout(0.1))\n#     model.add(tf.keras.layers.Dense(64,activation='relu'))\n#     model.add(tf.keras.layers.BatchNormalization())\n#     model.add(tf.keras.layers.Dropout(0.1))\n#     model.add(tf.keras.layers.Dense(32,activation='relu'))\n#     model.add(tf.keras.layers.Dense(10,activation='softmax'))\n#     model.compile(optimizer=\"Adam\",loss='categorical_crossentropy',metrics=['accuracy'])","metadata":{"execution":{"iopub.status.busy":"2023-07-16T08:51:13.798802Z","iopub.execute_input":"2023-07-16T08:51:13.799206Z","iopub.status.idle":"2023-07-16T08:51:13.806565Z","shell.execute_reply.started":"2023-07-16T08:51:13.799170Z","shell.execute_reply":"2023-07-16T08:51:13.805332Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"#model 6\n# with mirrored_strategy.scope():\n#     model=tf.keras.Sequential()\n#     model.add(tf.keras.layers.Conv2D(30,(2,2),strides=(1,1),padding='valid',\n#                                      activation='relu',input_shape=(32,32,3)))\n#     model.add(tf.keras.layers.Conv2D(30,(2,2),strides=(1,1),padding='valid',activation='relu'))\n#     model.add(tf.keras.layers.BatchNormalization())\n#     model.add(tf.keras.layers.AveragePooling2D(pool_size=(2,2),strides=None,padding='valid'))\n# #   model.add(tf.keras.layers.Conv2D(20,(2,2),strides=(1,1),padding='valid',activation='relu'))\n#     model.add(tf.keras.layers.Conv2D(15,(2,2),strides=(1,1),padding='valid',activation='relu'))\n# #     model.add(tf.keras.layers.Conv2D(15,(3,3),strides=(1,1),padding='valid',activation='relu'))\n#     model.add(tf.keras.layers.GroupNormalization(groups=3))\n#     model.add(tf.keras.layers.AveragePooling2D(pool_size=(2,2),strides=None,padding='valid'))\n#     model.add(tf.keras.layers.Conv2D(10,(2,2),strides=(1,1),padding='valid',activation='relu'))\n#     model.add(tf.keras.layers.Flatten())\n#     model.add(tf.keras.layers.Normalization())\n#     model.add(tf.keras.layers.Dense(128,activation='relu')) #reduce neurons?\n#     model.add(tf.keras.layers.BatchNormalization())\n#     model.add(tf.keras.layers.Dropout(0.3)) #0.1?\n#     model.add(tf.keras.layers.Dense(64,activation='relu'))\n#     model.add(tf.keras.layers.BatchNormalization())\n#     model.add(tf.keras.layers.Dropout(0.3)) #0.1?\n#     model.add(tf.keras.layers.Dense(32,activation='relu'))\n#     model.add(tf.keras.layers.Dense(10,activation='softmax'))\n#     model.compile(optimizer=\"Adam\",loss='categorical_crossentropy',metrics=['accuracy'])","metadata":{"execution":{"iopub.status.busy":"2023-07-16T08:51:13.808197Z","iopub.execute_input":"2023-07-16T08:51:13.808592Z","iopub.status.idle":"2023-07-16T08:51:14.256999Z","shell.execute_reply.started":"2023-07-16T08:51:13.808558Z","shell.execute_reply":"2023-07-16T08:51:14.255871Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"# with mirrored_strategy.scope():\n#     model=tf.keras.Sequential()\n#     model.add(tf.keras.layers.Conv2D(30,(3,3),strides=(1,1),padding='valid',\n#                                      activation='relu',input_shape=(32,32,3)))\n#     model.add(tf.keras.layers.Conv2D(30,(3,3),strides=(1,1),padding='valid',activation='relu'))\n#     model.add(tf.keras.layers.BatchNormalization())\n#     model.add(tf.keras.layers.AveragePooling2D(pool_size=(2,2),strides=None,padding='valid'))\n# #   model.add(tf.keras.layers.Conv2D(20,(2,2),strides=(1,1),padding='valid',activation='relu'))\n#     model.add(tf.keras.layers.Conv2D(15,(2,2),strides=(1,1),padding='valid',activation='relu'))\n# #     model.add(tf.keras.layers.Conv2D(15,(3,3),strides=(1,1),padding='valid',activation='relu'))\n#     model.add(tf.keras.layers.GroupNormalization(groups=3))\n#     model.add(tf.keras.layers.AveragePooling2D(pool_size=(2,2),strides=None,padding='valid'))\n#     model.add(tf.keras.layers.Conv2D(10,(2,2),strides=(1,1),padding='valid',activation='relu'))\n#     model.add(tf.keras.layers.Flatten())\n#     model.add(tf.keras.layers.Normalization())\n#     model.add(tf.keras.layers.Dense(128,activation='relu'))\n#     model.add(tf.keras.layers.BatchNormalization())\n#     model.add(tf.keras.layers.Dropout(0.1)) #0.1?\n#     model.add(tf.keras.layers.Dense(64,activation='relu'))\n#     model.add(tf.keras.layers.BatchNormalization())\n#     model.add(tf.keras.layers.Dropout(0.1)) #0.1?\n#     model.add(tf.keras.layers.Dense(32,activation='relu'))\n#     model.add(tf.keras.layers.Dense(10,activation='softmax'))\n#     model.compile(optimizer=\"Adam\",loss='categorical_crossentropy',metrics=['accuracy'])","metadata":{"execution":{"iopub.status.busy":"2023-07-16T10:05:48.916192Z","iopub.execute_input":"2023-07-16T10:05:48.917105Z","iopub.status.idle":"2023-07-16T10:05:49.230949Z","shell.execute_reply.started":"2023-07-16T10:05:48.917034Z","shell.execute_reply":"2023-07-16T10:05:49.230003Z"},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"code","source":"with mirrored_strategy.scope():\n    pool_net=tf.keras.Sequential()\n    pool_net.add(tf.keras.layers.InputLayer(input_shape=(32,32,3)))\n    pool_net.add(tf.keras.layers.AveragePooling2D(pool_size=(2,2),strides=None,padding='same'))\n    pool_net.add(tf.keras.layers.BatchNormalization())\n#     pool_net.add(tf.keras.layers.AveragePooling2D(pool_size=(2,2),strides=None,padding='same'))\n#     pool_net.add(tf.keras.layers.BatchNormalization())\n    pool_net.add(tf.keras.layers.Flatten())\n    pool_net.add(tf.keras.layers.Normalization())\n    pool_net.add(tf.keras.layers.Dense(128,activation='relu'))\n    pool_net.add(tf.keras.layers.BatchNormalization())\n    pool_net.add(tf.keras.layers.Dropout(0.4))\n    pool_net.add(tf.keras.layers.Dense(64,activation='relu'))\n    pool_net.add(tf.keras.layers.Dense(10,activation='softmax'))\n    pool_net.compile(optimizer=tf.keras.optimizers.Adam(),loss='categorical_crossentropy',metrics=['accuracy'])","metadata":{"execution":{"iopub.status.busy":"2023-07-16T13:03:45.600774Z","iopub.execute_input":"2023-07-16T13:03:45.601173Z","iopub.status.idle":"2023-07-16T13:03:45.764522Z","shell.execute_reply.started":"2023-07-16T13:03:45.601138Z","shell.execute_reply":"2023-07-16T13:03:45.763569Z"},"trusted":true},"execution_count":60,"outputs":[]},{"cell_type":"code","source":"pool_net.summary()","metadata":{"execution":{"iopub.status.busy":"2023-07-16T13:03:50.490006Z","iopub.execute_input":"2023-07-16T13:03:50.490630Z","iopub.status.idle":"2023-07-16T13:03:50.519009Z","shell.execute_reply.started":"2023-07-16T13:03:50.490596Z","shell.execute_reply":"2023-07-16T13:03:50.518141Z"},"trusted":true},"execution_count":61,"outputs":[{"name":"stdout","text":"Model: \"sequential_8\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n average_pooling2d_15 (Avera  (None, 16, 16, 3)        0         \n gePooling2D)                                                    \n                                                                 \n batch_normalization_23 (Bat  (None, 16, 16, 3)        12        \n chNormalization)                                                \n                                                                 \n flatten_8 (Flatten)         (None, 768)               0         \n                                                                 \n normalization_8 (Normalizat  (None, 768)              1537      \n ion)                                                            \n                                                                 \n dense_28 (Dense)            (None, 128)               98432     \n                                                                 \n batch_normalization_24 (Bat  (None, 128)              512       \n chNormalization)                                                \n                                                                 \n dropout_12 (Dropout)        (None, 128)               0         \n                                                                 \n dense_29 (Dense)            (None, 64)                8256      \n                                                                 \n dense_30 (Dense)            (None, 10)                650       \n                                                                 \n=================================================================\nTotal params: 109,399\nTrainable params: 107,600\nNon-trainable params: 1,799\n_________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"code","source":"#model.summary()","metadata":{"execution":{"iopub.status.busy":"2023-07-16T10:05:50.094877Z","iopub.execute_input":"2023-07-16T10:05:50.095465Z","iopub.status.idle":"2023-07-16T10:05:50.149129Z","shell.execute_reply.started":"2023-07-16T10:05:50.095430Z","shell.execute_reply":"2023-07-16T10:05:50.148363Z"},"trusted":true},"execution_count":38,"outputs":[{"name":"stdout","text":"Model: \"sequential_3\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n conv2d_12 (Conv2D)          (None, 30, 30, 30)        840       \n                                                                 \n conv2d_13 (Conv2D)          (None, 28, 28, 30)        8130      \n                                                                 \n batch_normalization_9 (Batc  (None, 28, 28, 30)       120       \n hNormalization)                                                 \n                                                                 \n average_pooling2d_6 (Averag  (None, 14, 14, 30)       0         \n ePooling2D)                                                     \n                                                                 \n conv2d_14 (Conv2D)          (None, 13, 13, 15)        1815      \n                                                                 \n group_normalization_3 (Grou  (None, 13, 13, 15)       30        \n pNormalization)                                                 \n                                                                 \n average_pooling2d_7 (Averag  (None, 6, 6, 15)         0         \n ePooling2D)                                                     \n                                                                 \n conv2d_15 (Conv2D)          (None, 5, 5, 10)          610       \n                                                                 \n flatten_3 (Flatten)         (None, 250)               0         \n                                                                 \n normalization_3 (Normalizat  (None, 250)              501       \n ion)                                                            \n                                                                 \n dense_12 (Dense)            (None, 128)               32128     \n                                                                 \n batch_normalization_10 (Bat  (None, 128)              512       \n chNormalization)                                                \n                                                                 \n dropout_6 (Dropout)         (None, 128)               0         \n                                                                 \n dense_13 (Dense)            (None, 64)                8256      \n                                                                 \n batch_normalization_11 (Bat  (None, 64)               256       \n chNormalization)                                                \n                                                                 \n dropout_7 (Dropout)         (None, 64)                0         \n                                                                 \n dense_14 (Dense)            (None, 32)                2080      \n                                                                 \n dense_15 (Dense)            (None, 10)                330       \n                                                                 \n=================================================================\nTotal params: 55,608\nTrainable params: 54,663\nNon-trainable params: 945\n_________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"code","source":"with mirrored_strategy.scope():\n    checkpoint= tf.keras.callbacks.ModelCheckpoint(filepath='/kaggle/working/cifar_10_pool_net_classifier_1.h5',\n                                                   save_weights_only=False,monitor='val_accuracy',\n                                                   save_best_only=True,save_freq=\"epoch\",)\n    early_stopping= tf.keras.callbacks.EarlyStopping(monitor='val_loss',patience=20,\n                                                     restore_best_weights=True)\n    def lr_scheduler(epoch,lr,epochs=100):\n        initial=0.005\n        if epoch<epochs*0.1:\n            return initial\n        elif epoch>epochs*0.1 and epoch<epochs*0.25:\n            lr*=tf.math.exp(-0.1)\n            return lr\n        else:\n            lr*=tf.math.exp(-0.008)\n            return lr\n    lr_scheduling=tf.keras.callbacks.LearningRateScheduler(lr_scheduler)","metadata":{"execution":{"iopub.status.busy":"2023-07-16T13:04:26.021025Z","iopub.execute_input":"2023-07-16T13:04:26.021795Z","iopub.status.idle":"2023-07-16T13:04:26.029816Z","shell.execute_reply.started":"2023-07-16T13:04:26.021761Z","shell.execute_reply":"2023-07-16T13:04:26.028673Z"},"trusted":true},"execution_count":62,"outputs":[]},{"cell_type":"code","source":"with mirrored_strategy.scope():\n    history = pool_net.fit(train_data.batch(100),epochs=200,validation_data=val_data.batch(100),\n                        callbacks=[checkpoint,early_stopping],use_multiprocessing=True)","metadata":{"execution":{"iopub.status.busy":"2023-07-16T13:04:32.152104Z","iopub.execute_input":"2023-07-16T13:04:32.152489Z","iopub.status.idle":"2023-07-16T14:09:43.727388Z","shell.execute_reply.started":"2023-07-16T13:04:32.152458Z","shell.execute_reply":"2023-07-16T14:09:43.725101Z"},"trusted":true},"execution_count":63,"outputs":[{"name":"stdout","text":"Epoch 1/200\n450/450 [==============================] - 29s 54ms/step - loss: 1.8900 - accuracy: 0.3350 - val_loss: 1.5961 - val_accuracy: 0.4336\nEpoch 2/200\n450/450 [==============================] - 25s 56ms/step - loss: 1.6592 - accuracy: 0.4076 - val_loss: 1.4907 - val_accuracy: 0.4734\nEpoch 3/200\n450/450 [==============================] - 29s 64ms/step - loss: 1.5930 - accuracy: 0.4315 - val_loss: 1.4360 - val_accuracy: 0.4956\nEpoch 4/200\n450/450 [==============================] - 30s 66ms/step - loss: 1.5419 - accuracy: 0.4495 - val_loss: 1.3904 - val_accuracy: 0.5060\nEpoch 5/200\n450/450 [==============================] - 30s 67ms/step - loss: 1.5068 - accuracy: 0.4620 - val_loss: 1.3641 - val_accuracy: 0.5180\nEpoch 6/200\n450/450 [==============================] - 36s 80ms/step - loss: 1.4806 - accuracy: 0.4738 - val_loss: 1.3285 - val_accuracy: 0.5306\nEpoch 7/200\n450/450 [==============================] - 25s 55ms/step - loss: 1.4614 - accuracy: 0.4770 - val_loss: 1.3092 - val_accuracy: 0.5374\nEpoch 8/200\n450/450 [==============================] - 24s 54ms/step - loss: 1.4418 - accuracy: 0.4859 - val_loss: 1.2905 - val_accuracy: 0.5450\nEpoch 9/200\n450/450 [==============================] - 24s 53ms/step - loss: 1.4211 - accuracy: 0.4926 - val_loss: 1.2814 - val_accuracy: 0.5464\nEpoch 10/200\n450/450 [==============================] - 25s 55ms/step - loss: 1.4066 - accuracy: 0.4979 - val_loss: 1.2601 - val_accuracy: 0.5546\nEpoch 11/200\n450/450 [==============================] - 26s 58ms/step - loss: 1.3901 - accuracy: 0.5021 - val_loss: 1.2442 - val_accuracy: 0.5590\nEpoch 12/200\n450/450 [==============================] - 24s 54ms/step - loss: 1.3787 - accuracy: 0.5079 - val_loss: 1.2380 - val_accuracy: 0.5658\nEpoch 13/200\n450/450 [==============================] - 24s 52ms/step - loss: 1.3695 - accuracy: 0.5128 - val_loss: 1.2265 - val_accuracy: 0.5670\nEpoch 14/200\n450/450 [==============================] - 25s 55ms/step - loss: 1.3601 - accuracy: 0.5121 - val_loss: 1.2095 - val_accuracy: 0.5730\nEpoch 15/200\n450/450 [==============================] - 24s 53ms/step - loss: 1.3454 - accuracy: 0.5192 - val_loss: 1.1980 - val_accuracy: 0.5784\nEpoch 16/200\n450/450 [==============================] - 24s 53ms/step - loss: 1.3409 - accuracy: 0.5211 - val_loss: 1.1944 - val_accuracy: 0.5822\nEpoch 17/200\n450/450 [==============================] - 25s 55ms/step - loss: 1.3305 - accuracy: 0.5225 - val_loss: 1.1835 - val_accuracy: 0.5830\nEpoch 18/200\n450/450 [==============================] - 24s 53ms/step - loss: 1.3206 - accuracy: 0.5311 - val_loss: 1.1733 - val_accuracy: 0.5870\nEpoch 19/200\n450/450 [==============================] - 24s 54ms/step - loss: 1.3110 - accuracy: 0.5309 - val_loss: 1.1680 - val_accuracy: 0.5982\nEpoch 20/200\n450/450 [==============================] - 24s 54ms/step - loss: 1.3074 - accuracy: 0.5343 - val_loss: 1.1559 - val_accuracy: 0.5980\nEpoch 21/200\n450/450 [==============================] - 24s 54ms/step - loss: 1.3038 - accuracy: 0.5347 - val_loss: 1.1486 - val_accuracy: 0.5978\nEpoch 22/200\n450/450 [==============================] - 24s 54ms/step - loss: 1.2962 - accuracy: 0.5348 - val_loss: 1.1398 - val_accuracy: 0.6062\nEpoch 23/200\n450/450 [==============================] - 24s 52ms/step - loss: 1.2888 - accuracy: 0.5369 - val_loss: 1.1326 - val_accuracy: 0.6046\nEpoch 24/200\n450/450 [==============================] - 24s 54ms/step - loss: 1.2837 - accuracy: 0.5404 - val_loss: 1.1295 - val_accuracy: 0.6068\nEpoch 25/200\n450/450 [==============================] - 24s 53ms/step - loss: 1.2766 - accuracy: 0.5435 - val_loss: 1.1211 - val_accuracy: 0.6124\nEpoch 26/200\n450/450 [==============================] - 24s 54ms/step - loss: 1.2751 - accuracy: 0.5427 - val_loss: 1.1234 - val_accuracy: 0.6066\nEpoch 27/200\n450/450 [==============================] - 24s 53ms/step - loss: 1.2634 - accuracy: 0.5473 - val_loss: 1.1124 - val_accuracy: 0.6080\nEpoch 28/200\n450/450 [==============================] - 24s 54ms/step - loss: 1.2702 - accuracy: 0.5477 - val_loss: 1.1164 - val_accuracy: 0.6146\nEpoch 29/200\n450/450 [==============================] - 25s 56ms/step - loss: 1.2596 - accuracy: 0.5480 - val_loss: 1.0992 - val_accuracy: 0.6154\nEpoch 30/200\n450/450 [==============================] - 24s 53ms/step - loss: 1.2533 - accuracy: 0.5508 - val_loss: 1.0929 - val_accuracy: 0.6228\nEpoch 31/200\n450/450 [==============================] - 25s 56ms/step - loss: 1.2498 - accuracy: 0.5538 - val_loss: 1.0960 - val_accuracy: 0.6186\nEpoch 32/200\n450/450 [==============================] - 25s 55ms/step - loss: 1.2413 - accuracy: 0.5588 - val_loss: 1.0884 - val_accuracy: 0.6206\nEpoch 33/200\n450/450 [==============================] - 25s 56ms/step - loss: 1.2383 - accuracy: 0.5589 - val_loss: 1.0885 - val_accuracy: 0.6212\nEpoch 34/200\n450/450 [==============================] - 25s 55ms/step - loss: 1.2408 - accuracy: 0.5545 - val_loss: 1.0875 - val_accuracy: 0.6204\nEpoch 35/200\n450/450 [==============================] - 34s 75ms/step - loss: 1.2309 - accuracy: 0.5620 - val_loss: 1.0760 - val_accuracy: 0.6266\nEpoch 36/200\n450/450 [==============================] - 44s 96ms/step - loss: 1.2325 - accuracy: 0.5575 - val_loss: 1.0760 - val_accuracy: 0.6274\nEpoch 37/200\n450/450 [==============================] - 29s 64ms/step - loss: 1.2225 - accuracy: 0.5616 - val_loss: 1.0678 - val_accuracy: 0.6318\nEpoch 38/200\n450/450 [==============================] - 25s 57ms/step - loss: 1.2259 - accuracy: 0.5605 - val_loss: 1.0656 - val_accuracy: 0.6280\nEpoch 39/200\n450/450 [==============================] - 25s 54ms/step - loss: 1.2161 - accuracy: 0.5639 - val_loss: 1.0612 - val_accuracy: 0.6290\nEpoch 40/200\n450/450 [==============================] - 25s 55ms/step - loss: 1.2222 - accuracy: 0.5628 - val_loss: 1.0550 - val_accuracy: 0.6318\nEpoch 41/200\n450/450 [==============================] - 27s 61ms/step - loss: 1.2098 - accuracy: 0.5698 - val_loss: 1.0524 - val_accuracy: 0.6300\nEpoch 42/200\n450/450 [==============================] - 26s 59ms/step - loss: 1.2089 - accuracy: 0.5633 - val_loss: 1.0482 - val_accuracy: 0.6322\nEpoch 43/200\n450/450 [==============================] - 25s 55ms/step - loss: 1.2125 - accuracy: 0.5671 - val_loss: 1.0474 - val_accuracy: 0.6358\nEpoch 44/200\n450/450 [==============================] - 26s 57ms/step - loss: 1.2068 - accuracy: 0.5692 - val_loss: 1.0422 - val_accuracy: 0.6372\nEpoch 45/200\n450/450 [==============================] - 25s 55ms/step - loss: 1.2042 - accuracy: 0.5674 - val_loss: 1.0430 - val_accuracy: 0.6442\nEpoch 46/200\n450/450 [==============================] - 25s 56ms/step - loss: 1.1967 - accuracy: 0.5713 - val_loss: 1.0414 - val_accuracy: 0.6412\nEpoch 47/200\n450/450 [==============================] - 24s 53ms/step - loss: 1.1918 - accuracy: 0.5742 - val_loss: 1.0278 - val_accuracy: 0.6508\nEpoch 48/200\n450/450 [==============================] - 24s 54ms/step - loss: 1.1960 - accuracy: 0.5709 - val_loss: 1.0326 - val_accuracy: 0.6406\nEpoch 49/200\n450/450 [==============================] - 27s 59ms/step - loss: 1.1871 - accuracy: 0.5747 - val_loss: 1.0203 - val_accuracy: 0.6450\nEpoch 50/200\n450/450 [==============================] - 24s 54ms/step - loss: 1.1909 - accuracy: 0.5732 - val_loss: 1.0258 - val_accuracy: 0.6396\nEpoch 51/200\n450/450 [==============================] - 28s 63ms/step - loss: 1.1916 - accuracy: 0.5736 - val_loss: 1.0287 - val_accuracy: 0.6456\nEpoch 52/200\n450/450 [==============================] - 24s 54ms/step - loss: 1.1846 - accuracy: 0.5764 - val_loss: 1.0100 - val_accuracy: 0.6470\nEpoch 53/200\n450/450 [==============================] - 25s 56ms/step - loss: 1.1838 - accuracy: 0.5768 - val_loss: 1.0110 - val_accuracy: 0.6526\nEpoch 54/200\n450/450 [==============================] - 25s 57ms/step - loss: 1.1800 - accuracy: 0.5756 - val_loss: 1.0060 - val_accuracy: 0.6514\nEpoch 55/200\n450/450 [==============================] - 25s 55ms/step - loss: 1.1786 - accuracy: 0.5784 - val_loss: 1.0065 - val_accuracy: 0.6502\nEpoch 56/200\n450/450 [==============================] - 24s 54ms/step - loss: 1.1741 - accuracy: 0.5812 - val_loss: 1.0065 - val_accuracy: 0.6450\nEpoch 57/200\n450/450 [==============================] - 23s 52ms/step - loss: 1.1707 - accuracy: 0.5848 - val_loss: 1.0005 - val_accuracy: 0.6558\nEpoch 58/200\n450/450 [==============================] - 24s 54ms/step - loss: 1.1711 - accuracy: 0.5821 - val_loss: 1.0013 - val_accuracy: 0.6526\nEpoch 59/200\n450/450 [==============================] - 24s 53ms/step - loss: 1.1740 - accuracy: 0.5788 - val_loss: 0.9948 - val_accuracy: 0.6584\nEpoch 60/200\n450/450 [==============================] - 24s 53ms/step - loss: 1.1674 - accuracy: 0.5815 - val_loss: 0.9892 - val_accuracy: 0.6608\nEpoch 61/200\n450/450 [==============================] - 24s 54ms/step - loss: 1.1629 - accuracy: 0.5842 - val_loss: 0.9874 - val_accuracy: 0.6594\nEpoch 62/200\n450/450 [==============================] - 24s 53ms/step - loss: 1.1629 - accuracy: 0.5846 - val_loss: 0.9919 - val_accuracy: 0.6562\nEpoch 63/200\n450/450 [==============================] - 24s 53ms/step - loss: 1.1591 - accuracy: 0.5829 - val_loss: 0.9904 - val_accuracy: 0.6526\nEpoch 64/200\n450/450 [==============================] - 24s 54ms/step - loss: 1.1568 - accuracy: 0.5856 - val_loss: 0.9798 - val_accuracy: 0.6642\nEpoch 65/200\n450/450 [==============================] - 24s 53ms/step - loss: 1.1529 - accuracy: 0.5854 - val_loss: 0.9823 - val_accuracy: 0.6544\nEpoch 66/200\n450/450 [==============================] - 25s 55ms/step - loss: 1.1573 - accuracy: 0.5880 - val_loss: 0.9740 - val_accuracy: 0.6644\nEpoch 67/200\n450/450 [==============================] - 24s 53ms/step - loss: 1.1565 - accuracy: 0.5862 - val_loss: 0.9782 - val_accuracy: 0.6644\nEpoch 68/200\n450/450 [==============================] - 25s 55ms/step - loss: 1.1447 - accuracy: 0.5902 - val_loss: 0.9674 - val_accuracy: 0.6696\nEpoch 69/200\n450/450 [==============================] - 24s 54ms/step - loss: 1.1516 - accuracy: 0.5885 - val_loss: 0.9696 - val_accuracy: 0.6640\nEpoch 70/200\n450/450 [==============================] - 26s 59ms/step - loss: 1.1461 - accuracy: 0.5891 - val_loss: 0.9722 - val_accuracy: 0.6612\nEpoch 71/200\n450/450 [==============================] - 27s 59ms/step - loss: 1.1460 - accuracy: 0.5894 - val_loss: 0.9627 - val_accuracy: 0.6638\nEpoch 72/200\n450/450 [==============================] - 24s 53ms/step - loss: 1.1424 - accuracy: 0.5903 - val_loss: 0.9629 - val_accuracy: 0.6640\nEpoch 73/200\n450/450 [==============================] - 31s 69ms/step - loss: 1.1477 - accuracy: 0.5901 - val_loss: 0.9657 - val_accuracy: 0.6628\nEpoch 74/200\n450/450 [==============================] - 28s 63ms/step - loss: 1.1396 - accuracy: 0.5906 - val_loss: 0.9527 - val_accuracy: 0.6642\nEpoch 75/200\n450/450 [==============================] - 27s 60ms/step - loss: 1.1418 - accuracy: 0.5889 - val_loss: 0.9558 - val_accuracy: 0.6698\nEpoch 76/200\n450/450 [==============================] - 26s 57ms/step - loss: 1.1350 - accuracy: 0.5950 - val_loss: 0.9491 - val_accuracy: 0.6708\nEpoch 77/200\n450/450 [==============================] - 26s 58ms/step - loss: 1.1327 - accuracy: 0.5928 - val_loss: 0.9483 - val_accuracy: 0.6702\nEpoch 78/200\n450/450 [==============================] - 25s 56ms/step - loss: 1.1368 - accuracy: 0.5935 - val_loss: 0.9578 - val_accuracy: 0.6718\nEpoch 79/200\n450/450 [==============================] - 26s 57ms/step - loss: 1.1358 - accuracy: 0.5926 - val_loss: 0.9611 - val_accuracy: 0.6656\nEpoch 80/200\n450/450 [==============================] - 24s 54ms/step - loss: 1.1288 - accuracy: 0.5949 - val_loss: 0.9450 - val_accuracy: 0.6762\nEpoch 81/200\n450/450 [==============================] - 25s 54ms/step - loss: 1.1301 - accuracy: 0.5955 - val_loss: 0.9506 - val_accuracy: 0.6690\nEpoch 82/200\n450/450 [==============================] - 25s 54ms/step - loss: 1.1263 - accuracy: 0.5959 - val_loss: 0.9418 - val_accuracy: 0.6752\nEpoch 83/200\n450/450 [==============================] - 24s 52ms/step - loss: 1.1297 - accuracy: 0.5954 - val_loss: 0.9397 - val_accuracy: 0.6730\nEpoch 84/200\n450/450 [==============================] - 25s 55ms/step - loss: 1.1233 - accuracy: 0.5987 - val_loss: 0.9418 - val_accuracy: 0.6668\nEpoch 85/200\n450/450 [==============================] - 24s 53ms/step - loss: 1.1206 - accuracy: 0.5974 - val_loss: 0.9349 - val_accuracy: 0.6770\nEpoch 86/200\n450/450 [==============================] - 24s 54ms/step - loss: 1.1221 - accuracy: 0.5985 - val_loss: 0.9403 - val_accuracy: 0.6816\nEpoch 87/200\n450/450 [==============================] - 25s 56ms/step - loss: 1.1171 - accuracy: 0.5999 - val_loss: 0.9293 - val_accuracy: 0.6810\nEpoch 88/200\n450/450 [==============================] - 24s 54ms/step - loss: 1.1203 - accuracy: 0.6000 - val_loss: 0.9429 - val_accuracy: 0.6750\nEpoch 89/200\n450/450 [==============================] - 28s 62ms/step - loss: 1.1168 - accuracy: 0.5986 - val_loss: 0.9300 - val_accuracy: 0.6758\nEpoch 90/200\n450/450 [==============================] - 24s 53ms/step - loss: 1.1188 - accuracy: 0.5967 - val_loss: 0.9360 - val_accuracy: 0.6752\nEpoch 91/200\n450/450 [==============================] - 24s 54ms/step - loss: 1.1170 - accuracy: 0.5978 - val_loss: 0.9292 - val_accuracy: 0.6820\nEpoch 92/200\n450/450 [==============================] - 24s 54ms/step - loss: 1.1137 - accuracy: 0.6014 - val_loss: 0.9339 - val_accuracy: 0.6768\nEpoch 93/200\n450/450 [==============================] - 24s 53ms/step - loss: 1.1158 - accuracy: 0.6003 - val_loss: 0.9256 - val_accuracy: 0.6834\nEpoch 94/200\n450/450 [==============================] - 25s 55ms/step - loss: 1.1109 - accuracy: 0.6007 - val_loss: 0.9248 - val_accuracy: 0.6806\nEpoch 95/200\n450/450 [==============================] - 24s 54ms/step - loss: 1.1070 - accuracy: 0.6013 - val_loss: 0.9196 - val_accuracy: 0.6768\nEpoch 96/200\n450/450 [==============================] - 25s 56ms/step - loss: 1.1063 - accuracy: 0.6048 - val_loss: 0.9160 - val_accuracy: 0.6776\nEpoch 97/200\n450/450 [==============================] - 23s 52ms/step - loss: 1.1085 - accuracy: 0.6012 - val_loss: 0.9125 - val_accuracy: 0.6836\nEpoch 98/200\n450/450 [==============================] - 24s 54ms/step - loss: 1.1020 - accuracy: 0.6086 - val_loss: 0.9208 - val_accuracy: 0.6820\nEpoch 99/200\n450/450 [==============================] - 24s 54ms/step - loss: 1.1041 - accuracy: 0.6040 - val_loss: 0.9095 - val_accuracy: 0.6896\nEpoch 100/200\n450/450 [==============================] - 24s 54ms/step - loss: 1.1110 - accuracy: 0.6022 - val_loss: 0.9136 - val_accuracy: 0.6866\nEpoch 101/200\n450/450 [==============================] - 24s 54ms/step - loss: 1.1004 - accuracy: 0.6055 - val_loss: 0.9122 - val_accuracy: 0.6888\nEpoch 102/200\n450/450 [==============================] - 26s 57ms/step - loss: 1.0985 - accuracy: 0.6050 - val_loss: 0.9136 - val_accuracy: 0.6846\nEpoch 103/200\n450/450 [==============================] - 25s 55ms/step - loss: 1.0995 - accuracy: 0.6068 - val_loss: 0.9070 - val_accuracy: 0.6872\nEpoch 104/200\n450/450 [==============================] - 24s 54ms/step - loss: 1.0989 - accuracy: 0.6069 - val_loss: 0.9090 - val_accuracy: 0.6826\nEpoch 105/200\n450/450 [==============================] - 24s 54ms/step - loss: 1.0973 - accuracy: 0.6071 - val_loss: 0.9005 - val_accuracy: 0.6894\nEpoch 106/200\n450/450 [==============================] - 24s 53ms/step - loss: 1.0958 - accuracy: 0.6086 - val_loss: 0.9085 - val_accuracy: 0.6842\nEpoch 107/200\n450/450 [==============================] - 25s 55ms/step - loss: 1.0960 - accuracy: 0.6068 - val_loss: 0.8999 - val_accuracy: 0.6904\nEpoch 108/200\n450/450 [==============================] - 26s 57ms/step - loss: 1.0954 - accuracy: 0.6071 - val_loss: 0.9059 - val_accuracy: 0.6874\nEpoch 109/200\n450/450 [==============================] - 25s 55ms/step - loss: 1.0917 - accuracy: 0.6067 - val_loss: 0.8972 - val_accuracy: 0.6942\nEpoch 110/200\n450/450 [==============================] - 25s 55ms/step - loss: 1.0916 - accuracy: 0.6104 - val_loss: 0.8966 - val_accuracy: 0.6948\nEpoch 111/200\n450/450 [==============================] - 24s 54ms/step - loss: 1.0936 - accuracy: 0.6070 - val_loss: 0.8992 - val_accuracy: 0.6852\nEpoch 112/200\n450/450 [==============================] - 25s 55ms/step - loss: 1.0879 - accuracy: 0.6111 - val_loss: 0.8923 - val_accuracy: 0.6928\nEpoch 113/200\n450/450 [==============================] - 27s 60ms/step - loss: 1.0894 - accuracy: 0.6088 - val_loss: 0.8948 - val_accuracy: 0.6916\nEpoch 114/200\n450/450 [==============================] - 45s 99ms/step - loss: 1.0904 - accuracy: 0.6070 - val_loss: 0.8923 - val_accuracy: 0.6900\nEpoch 115/200\n450/450 [==============================] - 34s 76ms/step - loss: 1.0835 - accuracy: 0.6123 - val_loss: 0.8916 - val_accuracy: 0.6912\nEpoch 116/200\n450/450 [==============================] - 34s 76ms/step - loss: 1.0910 - accuracy: 0.6083 - val_loss: 0.8918 - val_accuracy: 0.6926\nEpoch 117/200\n450/450 [==============================] - 26s 58ms/step - loss: 1.0853 - accuracy: 0.6136 - val_loss: 0.8911 - val_accuracy: 0.6884\nEpoch 118/200\n450/450 [==============================] - 26s 58ms/step - loss: 1.0798 - accuracy: 0.6148 - val_loss: 0.8904 - val_accuracy: 0.6908\nEpoch 119/200\n450/450 [==============================] - 26s 57ms/step - loss: 1.0843 - accuracy: 0.6129 - val_loss: 0.8919 - val_accuracy: 0.6914\nEpoch 120/200\n450/450 [==============================] - 27s 61ms/step - loss: 1.0788 - accuracy: 0.6116 - val_loss: 0.8804 - val_accuracy: 0.6968\nEpoch 121/200\n450/450 [==============================] - 25s 57ms/step - loss: 1.0775 - accuracy: 0.6135 - val_loss: 0.8822 - val_accuracy: 0.6988\nEpoch 122/200\n450/450 [==============================] - 27s 60ms/step - loss: 1.0764 - accuracy: 0.6156 - val_loss: 0.8853 - val_accuracy: 0.7002\nEpoch 123/200\n450/450 [==============================] - 27s 59ms/step - loss: 1.0750 - accuracy: 0.6155 - val_loss: 0.8779 - val_accuracy: 0.6966\nEpoch 124/200\n450/450 [==============================] - 28s 61ms/step - loss: 1.0780 - accuracy: 0.6147 - val_loss: 0.8814 - val_accuracy: 0.6930\nEpoch 125/200\n450/450 [==============================] - 27s 60ms/step - loss: 1.0712 - accuracy: 0.6162 - val_loss: 0.8818 - val_accuracy: 0.6906\nEpoch 126/200\n450/450 [==============================] - 27s 59ms/step - loss: 1.0745 - accuracy: 0.6150 - val_loss: 0.8884 - val_accuracy: 0.6972\nEpoch 127/200\n450/450 [==============================] - 26s 57ms/step - loss: 1.0745 - accuracy: 0.6162 - val_loss: 0.8853 - val_accuracy: 0.6950\nEpoch 128/200\n450/450 [==============================] - 27s 59ms/step - loss: 1.0710 - accuracy: 0.6149 - val_loss: 0.8748 - val_accuracy: 0.6990\nEpoch 129/200\n450/450 [==============================] - 27s 59ms/step - loss: 1.0772 - accuracy: 0.6126 - val_loss: 0.8765 - val_accuracy: 0.7042\nEpoch 130/200\n450/450 [==============================] - 26s 58ms/step - loss: 1.0758 - accuracy: 0.6143 - val_loss: 0.8785 - val_accuracy: 0.6974\nEpoch 131/200\n450/450 [==============================] - 31s 70ms/step - loss: 1.0724 - accuracy: 0.6146 - val_loss: 0.8769 - val_accuracy: 0.6948\nEpoch 132/200\n450/450 [==============================] - 30s 66ms/step - loss: 1.0762 - accuracy: 0.6156 - val_loss: 0.8782 - val_accuracy: 0.6988\nEpoch 133/200\n450/450 [==============================] - 27s 59ms/step - loss: 1.0684 - accuracy: 0.6163 - val_loss: 0.8668 - val_accuracy: 0.6974\nEpoch 134/200\n450/450 [==============================] - 35s 77ms/step - loss: 1.0617 - accuracy: 0.6168 - val_loss: 0.8683 - val_accuracy: 0.7030\nEpoch 135/200\n450/450 [==============================] - 50s 108ms/step - loss: 1.0677 - accuracy: 0.6179 - val_loss: 0.8618 - val_accuracy: 0.7022\nEpoch 136/200\n450/450 [==============================] - 27s 59ms/step - loss: 1.0666 - accuracy: 0.6172 - val_loss: 0.8674 - val_accuracy: 0.7024\nEpoch 137/200\n450/450 [==============================] - 27s 59ms/step - loss: 1.0687 - accuracy: 0.6149 - val_loss: 0.8671 - val_accuracy: 0.6992\nEpoch 138/200\n450/450 [==============================] - 27s 61ms/step - loss: 1.0590 - accuracy: 0.6201 - val_loss: 0.8695 - val_accuracy: 0.6982\nEpoch 139/200\n450/450 [==============================] - 26s 57ms/step - loss: 1.0648 - accuracy: 0.6186 - val_loss: 0.8673 - val_accuracy: 0.7044\nEpoch 140/200\n450/450 [==============================] - 27s 61ms/step - loss: 1.0596 - accuracy: 0.6193 - val_loss: 0.8585 - val_accuracy: 0.7064\nEpoch 141/200\n450/450 [==============================] - 25s 56ms/step - loss: 1.0619 - accuracy: 0.6219 - val_loss: 0.8616 - val_accuracy: 0.7042\nEpoch 142/200\n450/450 [==============================] - 26s 59ms/step - loss: 1.0616 - accuracy: 0.6208 - val_loss: 0.8684 - val_accuracy: 0.7028\nEpoch 143/200\n450/450 [==============================] - 28s 62ms/step - loss: 1.0615 - accuracy: 0.6173 - val_loss: 0.8592 - val_accuracy: 0.7036\nEpoch 144/200\n450/450 [==============================] - 27s 61ms/step - loss: 1.0616 - accuracy: 0.6190 - val_loss: 0.8629 - val_accuracy: 0.7002\nEpoch 145/200\n388/450 [========================>.....] - ETA: 3s - loss: 1.0522 - accuracy: 0.6221","output_type":"stream"},{"name":"stderr","text":"\nKeyboardInterrupt\n\n","output_type":"stream"}]},{"cell_type":"code","source":"#Implement Performance Scheduling?????????","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# with mirrored_strategy.scope():\n#     history = model.fit(train_data.batch(64),epochs=200,validation_data=val_data.batch(64),\n#                         callbacks=[checkpoint,early_stopping],use_multiprocessing=True)","metadata":{"execution":{"iopub.status.busy":"2023-07-16T13:01:43.987612Z","iopub.status.idle":"2023-07-16T13:01:43.988034Z","shell.execute_reply.started":"2023-07-16T13:01:43.987830Z","shell.execute_reply":"2023-07-16T13:01:43.987851Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model=tf.keras.models.load_model(\"/kaggle/working/cifar_10_pool_net_classifier_1.h5\")","metadata":{"execution":{"iopub.status.busy":"2023-07-16T14:10:18.790155Z","iopub.execute_input":"2023-07-16T14:10:18.790527Z","iopub.status.idle":"2023-07-16T14:10:18.946588Z","shell.execute_reply.started":"2023-07-16T14:10:18.790497Z","shell.execute_reply":"2023-07-16T14:10:18.945563Z"},"trusted":true},"execution_count":65,"outputs":[]},{"cell_type":"code","source":"with mirrored_strategy.scope():\n    predictions=model.predict(test_data.batch(10000))","metadata":{"execution":{"iopub.status.busy":"2023-07-16T14:10:22.010181Z","iopub.execute_input":"2023-07-16T14:10:22.011571Z","iopub.status.idle":"2023-07-16T14:10:32.669155Z","shell.execute_reply.started":"2023-07-16T14:10:22.011529Z","shell.execute_reply":"2023-07-16T14:10:32.668083Z"},"trusted":true},"execution_count":66,"outputs":[{"name":"stdout","text":"1/1 [==============================] - 11s 11s/step\n","output_type":"stream"}]},{"cell_type":"code","source":"def outputs(x):\n    a = np.zeros(x.shape)\n    a[np.where(x==np.max(x))] = 1\n    return a","metadata":{"execution":{"iopub.status.busy":"2023-07-16T14:10:32.671553Z","iopub.execute_input":"2023-07-16T14:10:32.671937Z","iopub.status.idle":"2023-07-16T14:10:32.679669Z","shell.execute_reply.started":"2023-07-16T14:10:32.671902Z","shell.execute_reply":"2023-07-16T14:10:32.678588Z"},"trusted":true},"execution_count":67,"outputs":[]},{"cell_type":"code","source":"for i in range(len(predictions)):\n     predictions[i]=outputs(predictions[i])","metadata":{"execution":{"iopub.status.busy":"2023-07-16T14:10:32.681458Z","iopub.execute_input":"2023-07-16T14:10:32.681913Z","iopub.status.idle":"2023-07-16T14:10:32.913057Z","shell.execute_reply.started":"2023-07-16T14:10:32.681874Z","shell.execute_reply":"2023-07-16T14:10:32.912085Z"},"trusted":true},"execution_count":68,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score","metadata":{"execution":{"iopub.status.busy":"2023-07-16T14:10:32.916359Z","iopub.execute_input":"2023-07-16T14:10:32.916716Z","iopub.status.idle":"2023-07-16T14:10:32.923571Z","shell.execute_reply.started":"2023-07-16T14:10:32.916678Z","shell.execute_reply":"2023-07-16T14:10:32.922420Z"},"trusted":true},"execution_count":69,"outputs":[]},{"cell_type":"code","source":"y_test=np.concatenate([y for x, y in test_data.batch(10000)],axis=0)","metadata":{"execution":{"iopub.status.busy":"2023-07-16T14:10:32.926878Z","iopub.execute_input":"2023-07-16T14:10:32.927243Z","iopub.status.idle":"2023-07-16T14:10:37.374136Z","shell.execute_reply.started":"2023-07-16T14:10:32.927215Z","shell.execute_reply":"2023-07-16T14:10:37.373074Z"},"trusted":true},"execution_count":70,"outputs":[]},{"cell_type":"code","source":"accuracy_score(predictions,y_test)","metadata":{"execution":{"iopub.status.busy":"2023-07-16T14:10:37.376201Z","iopub.execute_input":"2023-07-16T14:10:37.376548Z","iopub.status.idle":"2023-07-16T14:10:37.394976Z","shell.execute_reply.started":"2023-07-16T14:10:37.376515Z","shell.execute_reply":"2023-07-16T14:10:37.394081Z"},"trusted":true},"execution_count":71,"outputs":[{"execution_count":71,"output_type":"execute_result","data":{"text/plain":"0.5446"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}